{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataprosessering\n",
    "Denne innleveringen omhandler innlesing, tolkning og manupulering av data. Data finnes i\n",
    "mange ulike formater, f.eks. databaser, tabeller, lyd, bilde, osv., men i denne\n",
    "innleveringen skal vi fokusere på to typiske formater for lagring av data i tekstformat\n",
    "(CSV og JSON), og på lagring av data i form av \"arrays\". \n",
    "\n",
    "Denne innleveringen har 7 oppgaver til sammen. Avhengig av hvor mye erfaring du har med\n",
    "innlesing fra fil, nøstede datastrukturer, vektorer/matriser, og NumPy, kan oppgavene\n",
    "oppleves lette eller vanskeligere. Dersom du synes det er vanskelig: Gjør et ærlig\n",
    "forsøk, og hvis du ikke fikk det til, skriv en kort kommentar om hva du har prøvd og\n",
    "hvordan det gikk (du kan opprette en ny markdown-celle for å gjøre dette).  \n",
    "\n",
    "Som for tidligere innleveringer er denne notebooken en miks av oppgavetekst, startkode\n",
    "og tester som sjekker om koden du implementerer fungerer (ipytest). Temaene for\n",
    "oppgavene er gjennomgått i videoer som hører til denne modulen.  \n",
    "\n",
    "Vi importerer først bibliotekene vi skal bruke. Merk at veldig mange \"data\n",
    "science\"-eksempler bruker Pandas-biblioteket for å lese inn data i tekstformat. Det skal\n",
    "vi ikke gjøre her - vi bruker heller `csv`- og `json`-modulene som er \"innebygget\" i\n",
    "Python. Hensikten med dette er å få en bedre intuisjon for hvordan konverteringen fra\n",
    "tekst foregår. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports (don't add extra imports, like e.g. pandas)\n",
    "import csv\n",
    "import json\n",
    "import ipytest\n",
    "import numpy as np  # Standard short name for NumPy\n",
    "from pathlib import Path\n",
    "from numpy.typing import NDArray\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up pytest for Jupyter notebooks\n",
    "ipytest.autoconfig()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 1: Opprette array og finne gjennomsnitt\n",
    "Skriv kode som oppretter et NumPy-array som heter `X` og som inneholder verdiene vist\n",
    "under. Bruk funksjonen `np.mean()` til å regne ut \n",
    "1. Gjennomsnittsverdien for hele arrayet\n",
    "2. Gjennomsnittsverdiene for hver kolonne\n",
    "\n",
    "Bruk `print` for å skrive ut hele arrayet, samt svarene på alle spørsmålene over. (Tips:\n",
    "Finn NumPy-dokumentasjonen og sjekk ut argumentet \"`axis`\" for `np.mean()`).\n",
    "\n",
    "$$ X = \\begin{bmatrix} 14.2 & 75.3 & 2.3 \\\\ 12.7 & 133.5 & 5.9 \\\\ 18.8 & 54.0 & -1.1\n",
    "\\\\ 8.4 & 109.9 & 3.1 \\\\ \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add your code here\n",
    "pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 2: Normalisere data\n",
    "I maskinlæring og AI brukes ofte data der forskjellige \"features\" (ting man observerer)\n",
    "har ulike størrelsesordener. For eksempel: En voksen person er gjerne mellom 1,4 og 2,0\n",
    "meter høy, og veier mellom cirka 40 og 120 kg. Hvis man bruker disse størrelsene direkte i en\n",
    "maskinlæringsalgoritme, vil vekt ha en tendens til å \"dominere\", siden tallene for vekt\n",
    "er større enn tallene for høyde. Rent matematisk er er også ofte nyttig at verdiene er\n",
    "små (gjerne med absoluttverdier mellom 0 og 1), og at de er \"sentrert\" rundt null, dvs.\n",
    "at gjennomsnittsverdien er null. \n",
    "\n",
    "Vi kan normalisere ulike verdier gjennom å beregne såkalt\n",
    "[\"Z-score\"](https://en.wikipedia.org/wiki/Standard_score), også kalt \"standard score\".\n",
    "\n",
    "$$z = \\frac{x-\\mu}{\\sigma}$$\n",
    "\n",
    "der $x$ er den opprinnelige verdien, $\\mu$ er gjennomsnittsverdien, og $\\sigma$ er\n",
    "standardavviket. Merk at Z-score må beregnes for hver enkelt type observasjon, dvs. for\n",
    "hver kolonne i datasettet. Metoden fungerer best når datasettet følger en\n",
    "normalfordeling, men fungerer også fint for mange andre fordelinger.\n",
    "\n",
    "Hvis en person veier $x$=60 kg, gjennomsnittsvekten i datasettet\n",
    "er $\\mu$=70 kg, og standardavviket er $\\sigma$=20 kg, er z-score for denne vekten\n",
    "\n",
    "$$z = \\frac{60 - 70}{20} = \\frac{-10}{20} = -0.5$$\n",
    "\n",
    "*Implementer en funksjon som normaliserer en matrise med data gjennom å beregne Z-score\n",
    "for hver kolonne. Bruk NumPy-funksjoner og matematiske operasjoner som opererer på hele\n",
    "arrayet (unngå å \"loope over datasettet\", om du kan). Normaliser kun kolonnene som er\n",
    "indikert med det boolske arrayet norm_col.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_data_zscore(X: NDArray, norm_col: NDArray) -> NDArray:\n",
    "    \"\"\"Normalize data columns by subtracting mean and dividing by std.dev. (\"z-score\")\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X: NDArray\n",
    "        Numpy array (matrix) with numerical data, shape (n_samples, n_features)\n",
    "    norm_col: NDarray\n",
    "        Boolean vector, shape (n_features,).\n",
    "        Set norm_col[i] = True to indicate that column i should be normalized.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_norm\n",
    "        Normalized version of X. In columns indicated by norm_col, the mean column value\n",
    "        is first subtracted, and the resulting value is scaled by dividing with the\n",
    "        column standard deviation.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    Numpy methods np.copy, np.mean() and np.std() could be useful.\n",
    "    See also https://en.wikipedia.org/wiki/Standard_score\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "\n",
    "def test_normalize_data_zscore():\n",
    "    \"\"\"Test Z-score normalization of specific columns in dataset\"\"\"\n",
    "    X = np.array(\n",
    "        [[73.0, 61.0, 18.0], [27.0, 76.0, 63.0], [22.0, 88.0, 56.0], [70.0, 43.0, 83.0]]\n",
    "    )\n",
    "    col_norm = np.array([True, False, True])\n",
    "    X_norm = normalize_data_zscore(X, col_norm)\n",
    "    assert np.allclose(\n",
    "        X_norm,\n",
    "        np.array(\n",
    "            [\n",
    "                [1.05975976, 61.0, -1.57127047],\n",
    "                [-0.8901982, 76.0, 0.33973416],\n",
    "                [-1.10215015, 88.0, 0.04246677],\n",
    "                [0.93258859, 43.0, 1.18906955],\n",
    "            ]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oppgave 3: Lese CSV-fil\n",
    "Skriv kode som leser data fra fila `winequality-white.csv` (i mappa `datasets`) og returnerer en liste med\n",
    "overskrifter for hver kolonne, og en \"liste av lister\" med de numeriske dataene, der\n",
    "hvert element i lista tilsvarer en rad (en linje) i tekstfila.\n",
    "\n",
    "Merk: Bruk klasser / funksjoner fra `csv`-modulen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dataset_csv(\n",
    "    csv_file_path: Path | str,\n",
    "    delimiter: str,\n",
    ") -> tuple[list[str], list[list[str]]]:\n",
    "    \"\"\"Read dataset saved as CSV text file\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    csv_file_path: Path | str\n",
    "        Path to CSV file\n",
    "    delimiter: str\n",
    "        String symbol(s) indicating separation between columns\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    header: list[str]\n",
    "        List with header text for each column in dataset\n",
    "\n",
    "    data: list[list[str]]]\n",
    "        Nested list with numeric data from dataset.\n",
    "        Each element is a list corresponding to a row in the dataset.\n",
    "        Each element of the \"inner list\" is a string(!) with the data\n",
    "        for a given row and column.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "\n",
    "def test_read_dataset_csv_1():\n",
    "    header, data = read_dataset_csv(\"datasets/winequality-white.csv\", \";\")\n",
    "    assert len(header) == 12\n",
    "    assert header[5] == \"free sulfur dioxide\"\n",
    "    assert header[11] == \"quality\"\n",
    "    assert len(data) == 4898\n",
    "    assert len(data[0]) == 12\n",
    "    assert data[42][0] == \"7\"\n",
    "    assert data[42][7] == \"0.9954\"\n",
    "\n",
    "\n",
    "def test_read_dataset_csv_3():\n",
    "    header, data = read_dataset_csv(\"datasets/palmer_penguins.csv\", \",\")\n",
    "    assert header == [\n",
    "        \"species\",\n",
    "        \"island\",\n",
    "        \"culmen_length_mm\",\n",
    "        \"culmen_depth_mm\",\n",
    "        \"flipper_length_mm\",\n",
    "        \"body_mass_g\",\n",
    "        \"sex\",\n",
    "    ]\n",
    "    assert len(data) == 344\n",
    "    assert len(data[0]) == 7\n",
    "    assert data[42] == [\"Adelie\", \"Dream\", \"36\", \"18.5\", \"186\", \"3100\", \"FEMALE\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 4: Lese og normalisere data fra CSV-fil\n",
    "Implementer en funksjon som \n",
    "- leser inn datasettet som er lagret i `datasets/winequality-white.csv`\n",
    "- konverterer datasettet til et NumPy-array med datatype `np.float32`\n",
    "- normaliserer alle verdiene (Z-score) *unntatt* den siste kolonna (\"quality\")\n",
    "\n",
    "Bruk gjerne funksjonene som du allerede har implementert over (unngå klipp-og-lim, om du\n",
    "kan)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_normalize_wine_quality(\n",
    "    wine_quality_csv_path: Path | str,\n",
    ") -> tuple[list[str], NDArray]:\n",
    "    \"\"\"Read and normalize wine quality dataset\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    header: list[str]\n",
    "        List of column headers\n",
    "    X_norm: NDArray[np.float32]\n",
    "        Normalized version of wine quality dataset\n",
    "        Shape (n_samples, n_features)\n",
    "        Last column (\"quality\") is NOT normalized\n",
    "    \"\"\"\n",
    "\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "\n",
    "def test_read_normalize_wine_quality():\n",
    "    header, X_norm = read_normalize_wine_quality(\"datasets/winequality-white.csv\")\n",
    "    assert header == [  'fixed acidity', 'volatile acidity', 'citric acid', \n",
    "                        'residual sugar', 'chlorides', 'free sulfur dioxide', \n",
    "                        'total sulfur dioxide', 'density', 'pH', \n",
    "                        'sulphates', 'alcohol', 'quality']  # fmt: skip\n",
    "    assert X_norm.shape == (4898, 12)\n",
    "    assert np.allclose(X_norm[0], np.array([ \n",
    "        0.17209677, -0.08176959,  0.21328036,  2.8213494,  -0.03535487,  0.56993145,\n",
    "        0.74456507,  2.3315275,  -1.2469205,  -0.34918445, -1.3931531,   6.        ]))  # fmt: skip\n",
    "    assert np.allclose(X_norm[2048], np.array([\n",
    "        -0.06493103,  0.5135615,   0.87439656,  0.12000002,  0.19352268, -0.37094605,\n",
    "         0.39157180,  0.49242657, -0.31967650, -0.61207900, -0.82427645,  5.        ]))  # fmt: skip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 5: Lese JSON-fil\n",
    "Implementer en funksjon som leser inn informasjon om Nobelprisen fra JSON-fila\n",
    "`datasets/nobel_prize.json`, og som returnerer en liste over alle Nobelprisvinnerne\n",
    "innenfor et gitt fagfelt, i kronologisk rekkefølge. \n",
    "\n",
    "Merk at JSON-fila utgjør en dypt \"nøstet\" struktur, som oversettes til en dictionary med\n",
    "inneholder mange nivåer av dictionaries og lister når den leses inn. Du må selv skaffe\n",
    "deg oversikt over datastrukturen og hente ut informasjonen du trenger. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nobel_laureates(json_file_path: Path | str, category: str) -> list[str]:\n",
    "    \"\"\"Return full name of all Nobel prize winners (laureates) in given category\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    json_file_path: Path | str\n",
    "        Path to JSON file (str or pathlib.Path) with Nobel prizes\n",
    "    category: str\n",
    "        String indicating Nobel prize category\n",
    "        (e.g. 'medicine' or 'literature')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    winners: str\n",
    "        List of full names for every Nobel prize winner in given category, ordered\n",
    "        chronologically from first to last. In years with multiple winners, winners are\n",
    "        listed in the same order as they are listed in the JSON file. Example for\n",
    "        literature: (['Sully Prudhomme', ..., 'Jon Fosse'])\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "\n",
    "def test_nobel_laureates_1():\n",
    "    names = nobel_laureates(\"datasets/nobel_prize.json\", \"literature\")\n",
    "    assert len(names) == 120\n",
    "    assert names[0] == \"Sully Prudhomme\"\n",
    "    assert names[19] == \"Knut Hamsun\"\n",
    "    assert names[-1] == \"Jon Fosse\"\n",
    "\n",
    "\n",
    "def test_nobel_laureates_2():\n",
    "    names = nobel_laureates(\"datasets/nobel_prize.json\", \"physics\")\n",
    "    assert len(names) == 225\n",
    "    assert names[0] == \"Wilhelm Conrad Röntgen\"\n",
    "    assert names[5] == \"Marie Curie\"\n",
    "    assert names[-2] == \"Ferenc Krausz\"\n",
    "\n",
    "\n",
    "def test_nobel_laureates_3():\n",
    "    names = nobel_laureates(\"datasets/nobel_prize.json\", \"medicine\")\n",
    "    assert len(names) == 229\n",
    "    assert names[0] == \"Emil von Behring\"\n",
    "    assert names[189] == \"Harald zur Hausen\"\n",
    "    assert names[-1] == \"Gary Ruvkun\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 6: Implementere klasse for PCA\n",
    "Fyll ut koden for metodene fit() og transform() for klassen \"PCA\" under. Koden skal\n",
    "baseres på beregning av kovariansmatrise for et datasett, og egenverdier og egenvektorer\n",
    "for denne kovariansmatrisa, som beskrevet i videoer tilhørende denne modulen. Det eneste\n",
    "eksterne biblioteket som trengs er NumPy. Det er ikke lov å bruke ferdige implementasjoner av PCA. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PCA:\n",
    "    \"\"\"Class for fitting a PCA model to data and for transforming data\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    n_components : int\n",
    "        Number of principal components (eigenvectors with largest eigenvalues) to use\n",
    "    mean: NDArray, shape (n_samples,)\n",
    "        Mean value of each column in data that the model is fitted to\n",
    "    eigenvalues : NDArray, shape (n_features,)\n",
    "        Eigenvalues of data covariance matrix, sorted by value (descending)\n",
    "    eigenvectors : NDArray, shape (n_features, n_features)\n",
    "        Eigenvectors of data covariance matrix, sorted according to their\n",
    "        corresponding eigenvalues (descending).\n",
    "    self.components : NDArray, shape (n_features, n_components)\n",
    "        The n_components first eigenvectors, corresponding to the largest eigenvalues\n",
    "        (i.e. the directions in data space with most variance)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_components: int):\n",
    "        \"\"\"Initialize PCA object\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_components : int\n",
    "            Number of principal components (eigenvectors with largest eigenvalues) to use\n",
    "\n",
    "        \"\"\"\n",
    "        self.n_components = n_components\n",
    "        self.mean = None\n",
    "        self.eigenvalues = None\n",
    "        self.eigenvectors = None\n",
    "        self.components = None\n",
    "\n",
    "    def fit(self, X: NDArray) -> None:\n",
    "        \"\"\"Fit PCA model to data matrix\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: NDArray, shape (n_samples, n_features)\n",
    "            Data matrix used to fit (\"train\") PCA model\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        The fit function calculates and sets the following attributes (see doc. of class\n",
    "        attriburtes for details):\n",
    "        - mean\n",
    "        - eigenvalues\n",
    "        - eigenvectors\n",
    "        - components\n",
    "\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    def transform(self, X: NDArray) -> NDArray:\n",
    "        \"\"\"Transform data from original features to PCA component coordinates\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X: NDarray, shape (n_samples, n_features)\n",
    "            Data matrix to be transformed to PCA coordinates\n",
    "            The matrix can be the same as the matrix used to fit the model,\n",
    "            or it can be a different matrix with the same type of data\n",
    "            (same features)\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        X_pca: NDArray, shape (n_samples, n_components)\n",
    "            Matrix with data transformed to principal component coordinates.\n",
    "\n",
    "        \"\"\"\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%ipytest\n",
    "\n",
    "\n",
    "def test_pca_fit():\n",
    "    X = np.random.multivariate_normal(\n",
    "        mean=[0, -1, 0.5, 2],\n",
    "        cov=[[1, 0.7, 0, 0], [0.7, 1, 0.3, 0], [0, 0.3, 1, 0.1], [0, 0, 0.1, 1]],\n",
    "        size=10000,\n",
    "    )\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X)\n",
    "    assert np.allclose(pca.mean, [0, -1, 0.5, 2], atol=0.1)\n",
    "    assert pca.eigenvectors.shape == (4, 4)\n",
    "    assert np.allclose(np.abs(pca.components[:, 0]), [0.64, 0.70, 0.28, 0.04], atol=0.1)\n",
    "    assert np.allclose(np.abs(pca.components[:, 1]), [0.27, 0.03, 0.64, 0.71], atol=0.1)\n",
    "\n",
    "\n",
    "def test_pca_transform():\n",
    "    X = np.random.multivariate_normal(\n",
    "        mean=[0, -1, 0.5, 2],\n",
    "        cov=[[1, 0.7, 0, 0], [0.7, 1, 0.3, 0], [0, 0.3, 1, 0.1], [0, 0, 0.1, 1]],\n",
    "        size=10000,\n",
    "    )\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X)\n",
    "    X_test = np.array([[-0.3, -1.1, 0, 1.5], [0.7, -0.5, 1, 1]])\n",
    "    X_test_pca = pca.transform(X_test)\n",
    "    assert X_test_pca.shape == (2, 2)\n",
    "    # Hard to test exact values because direction of components changes based on random input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oppgave 7: Les, normalisér og transformer datasett til PCA-koordinater\n",
    "- Les inn datasettet `datasets/winequality-white.csv`. \n",
    "- Opprett en X-matrise som inneholder alle kolonnene unntatt den siste (\"quality\"-kolonna), og normaliser hver av de 11\n",
    "featurene i datasettet med z-score. \n",
    "- Lag et PCA-objekt basert på klassen du har implementert, og spesifiser at kun 2\n",
    "  komponenter skal brukes. Bruk fit() for å \"trene\" PCA-modellen på det normaliserte datasettet.\n",
    "- Bruk transform() for å transformere datasettet til 2 PCA-koordinater\n",
    "- Plott det transformerte datasettet med matplotlib (kode for dette er allerede oppgitt under)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The transformed data matrix should be called X_pca for the plotting below to work\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting av PCA-transformerte verdier\n",
    "n_plot_points = 500\n",
    "plt.scatter(\n",
    "    x=X_pca[0:n_plot_points, 0],\n",
    "    y=X_pca[0:n_plot_points, 1],\n",
    "    c=data[0:n_plot_points, -1],  # Use \"quality\" for coloring data points\n",
    "    cmap=\"jet\",\n",
    ")\n",
    "plt.xlabel(\"Principal component 1\")\n",
    "plt.ylabel(\"Principal component 2\")\n",
    "plt.xlim([-4.5, 4.5])\n",
    "plt.ylim([-4.5, 4.5])\n",
    "_ = plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hvis alt fungerer bør du kunne se at de beste vinene (de som har kvalitet 7 og 8) er\n",
    "gruppert i den ene enden av aksen som tilsvarer principal component 1. Gratulerer, i så\n",
    "fall! Her ser man også at PCA kan \"komprimere\" data (dvs. data spredt over 11 ulike\n",
    "features), og at visualisering av de første 2 komponentene allerede gir oss interessant informasjon."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "intro-ml-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
